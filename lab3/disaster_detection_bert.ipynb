{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6w6mhl0GOjk"
   },
   "source": [
    "## Disaster or not: Text Classification using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "FLs8SMhVGOjl",
    "outputId": "53131bfb-b59f-49bb-9ff9-4ec4b2d9c9fb"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/ravi-ilango/odsc2020_nlp/blob/main/lab1/disaster_data.zip?raw=true -O disaster_data.zip\n",
    "\n",
    "!unzip disaster_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "6J4BJ_ZpJ9tx",
    "outputId": "56cd037a-ca4c-49fb-94fc-52a248a2a4c6"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ahHXdOHsKLHt",
    "outputId": "3389aeae-81ae-4bf5-ef1b-8d50c2eca239"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkU5XHhZSaYT"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pkxnXrbHJWe"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pexPsED6GOjt"
   },
   "outputs": [],
   "source": [
    "model_path = './bert_disaster_detection_state_dict.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5ZsT6bGOjw"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "QX8SHDxIanDm",
    "outputId": "0f77d1c2-41fe-4098-bac3-0a0860555e5c"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# queries are stored in the variable query_text\n",
    "# correct intent labels are stored in the variable labels\n",
    "#\n",
    "query_text = pd.read_csv('./disaster_data/train.csv').text.values\n",
    "labels = pd.read_csv('./disaster_data/train.csv').target.values\n",
    "\n",
    "print(query_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "QGBCR4tyTpff",
    "outputId": "01c61a91-19e1-418c-ad69-b8fc74d2c25e"
   },
   "outputs": [],
   "source": [
    "plt.hist(labels)\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('count')\n",
    "plt.title('target distribution')\n",
    "plt.xticks(np.arange(len(np.unique(labels))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbZD4NT0X8NU"
   },
   "source": [
    "### Prepare Data: Convert to tokens and add special tokens [CLS] and [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "4AjhHhbmU-gh",
    "outputId": "4140bb6b-5c67-4579-f4ee-4df750d9609b"
   },
   "outputs": [],
   "source": [
    "# add special tokens for BERT to work properly\n",
    "sentences = [\"[CLS] \" + query + \" [SEP]\" for query in query_text]\n",
    "print(sentences[1])\n",
    "\n",
    "# Tokenize with BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QR_8UVhyGOj5"
   },
   "source": [
    "### Prepare Data: Pad tokens to create sequences of constant length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-w9-TWSXL-L"
   },
   "outputs": [],
   "source": [
    "# Maximum sequence length. \n",
    "MAX_LEN = 150\n",
    "\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIdLCbrkGOj8"
   },
   "source": [
    "### Prepare Data\n",
    "Create attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drVsf9SCXUf8"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptLywUVhXxAg"
   },
   "source": [
    "### Split into train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPrG98fJXWrh"
   },
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2018, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "p8LYjWuBTooR",
    "outputId": "2d156ab3-4a8e-4343-ff76-f0cf3fad546e"
   },
   "outputs": [],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCzTABSaGOkC"
   },
   "source": [
    "### Convert data into torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvWkX6CTGOkC"
   },
   "outputs": [],
   "source": [
    "# Convert data into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sj3swD8IGOkF"
   },
   "source": [
    "### Create a data generator (iterator) for the train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uq3uMXwnGOkF"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of train data with torch DataLoader \n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create an iterator of validation data with torch DataLoader \n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxDd2eiQX0Q_"
   },
   "source": [
    "### Load pretrained BERT model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "uVZIZUN0UTL4",
    "outputId": "ba168394-e2f0-4f2b-df11-5daeaf820ea2"
   },
   "outputs": [],
   "source": [
    "# specify GPU device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print (torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "FxVF3J24XZYV",
    "outputId": "cd2ac663-8ccb-4e1b-8252-b38b8998c4bd"
   },
   "outputs": [],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
    "\n",
    "num_labels = 2\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                      num_labels=num_labels)\n",
    "model.to(device)\n",
    "\n",
    "# BERT fine-tuning parameters\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=2e-5,\n",
    "                     warmup=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "yeqZoDIyGOkN",
    "outputId": "3b7257e6-f3c2-45e9-8c04-ed86066dfd3d"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(model_path):\n",
    "    print (\"Loading weights from saved model...\")\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxc-v5RWGOkQ"
   },
   "source": [
    "### Model Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rqqU_V-GOkQ"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer):\n",
    "\n",
    "    model.train()  \n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(iterator):\n",
    "        \n",
    "        #retrieve input data\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        #resets the gradients after every batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "        \n",
    "        # loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rybJV8uRGOkT"
   },
   "source": [
    "### Model Evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Bcl2EmiGOkT"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# Evaluate\n",
    "def evaluate(model, iterator):\n",
    "    \n",
    "    #initialize every epoch\n",
    "    epoch_acc = 0\n",
    "\n",
    "    #deactivating dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        #retrieve input data\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        #deactivates autograd\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions\n",
    "            logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)    \n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)    \n",
    "        epoch_acc += tmp_eval_accuracy\n",
    "        \n",
    "    return epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJ8MxrmPXrj_"
   },
   "source": [
    "### Train and Validate\n",
    "This step takes ~4min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "9zxNbWGWGOkW",
    "outputId": "32d1a58c-17ce-461b-bf76-b50b11032802"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 2\n",
    "best_valid_acc = 0\n",
    "\n",
    "# BERT training loop\n",
    "for _ in trange(N_EPOCHS, desc=\"Epoch\"):  \n",
    "\n",
    "    #train the model\n",
    "    train_loss = train(model, train_dataloader, optimizer)\n",
    "    \n",
    "    #evaluate the model\n",
    "    valid_acc = evaluate(model, validation_dataloader)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        print (\"saving model ...\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga-WimCQGOkZ"
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOoGLAHsGOkZ"
   },
   "outputs": [],
   "source": [
    "#load weights\n",
    "model.to('cpu')\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "#inference\n",
    "def prepare_text(sentence, MAX_LEN = 150):\n",
    "    sentence = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "    \n",
    "    # Tokenize with BERT tokenizer\n",
    "    tokenized_text = tokenizer.tokenize(sentence)\n",
    "    \n",
    "    # Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    input_ids = pad_sequences([input_ids], maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "    \n",
    "    # Create attention masks\n",
    "    attention_masks = []\n",
    "    # Create a mask of 1s for each token followed by 0s for padding\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "    \n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "    \n",
    "    return input_ids, attention_masks\n",
    "\n",
    "def predict(model, sentence):\n",
    "    \n",
    "    input_ids, attention_masks = prepare_text(sentence)\n",
    "    \n",
    "    prediction = model(input_ids, token_type_ids=None, attention_mask=attention_masks)    \n",
    "\n",
    "    return prediction.detach().cpu().numpy()\n",
    "\n",
    "def disaster_or_not(logits):\n",
    "    pred = np.argmax(logits, axis=1)[0]\n",
    "    return 'Disaster' if pred == 1 else 'Not a disaster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t227g_VuGOkb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "138KWbajGOkf",
    "outputId": "9a949bb4-66ad-41a6-b72d-1f5e1130a0d0"
   },
   "outputs": [],
   "source": [
    "logits = predict(model, \"Forest fire near La Ronge Sask. Canada\")\n",
    "disaster_or_not(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Wu2uBSz0GOki",
    "outputId": "98093000-07a0-4ff1-97a6-867cfc5c379d"
   },
   "outputs": [],
   "source": [
    "logits = predict(model, \"The weather is awesome\")\n",
    "disaster_or_not(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2pnJ1xjGOkl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vEpMVvuGOkn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "bert_lab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
